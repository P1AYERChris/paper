**4. 子课题四---"垂直领域大模型示范研究"工作内容及进展**

1.  十月工作内容与进展（总结）

- 总体目标（承接九月）

  - 在"三江源/青藏高原"数据管线已打通基础上，重点推进"端到端训练正确性 +
    工程稳定性 +
    可观测性"，确保模型能稳定前向/反向，建立可复现的训练基线，为后续性能与精度优化铺路。

- 端到端训练正确性修复

  - 层次-图一致性问题定位与修复：发现 pool 后节点数与图边索引不匹配导致
    CUDA device-side assert。

  - 实施严格重映射
    remap_hierarchy_and_graphs_strict：依据层次映射中"实际使用的父节点
    key"，对 medium/coarse 两层的 river/causal 图整体裁剪并重编号为
    0..K-1 连续，同步更新
    valid_basin_ids/num_nodes/edge_index/edge_attr。

  - 在 SpatioTemporalBlock 入口加入运行期断言：river 边索引 \< N，causal
    边索引 \< N\*F；训练前的 SANITY 日志输出三尺度 max
    索引与期望上界，确保进入前向前即暴露问题。

- 模型结构与稳定性增强

  - 引入 per-feature latent
    表达：保留每变量通道的隐藏状态，避免过早信息丢失；用残差融合（res_scale=0.5）平滑深层叠加。

  - 局部 LayerNorm 策略：按时间步在 per-feature 分支做 LN，替代一次性大
    reshape 的全局归一化，降低显存与数值漂移风险。

  - GraphPooling 安全化：使用父键 max_key+1
    的输出大小，兼容（但在严格重映射后键值已连续，可退回
    len(keys)）；GraphUnpooling 保持 dtype 一致性、边界检查。

  - 训练头：可学习缩放 +
    sigmoid，配合变量归一化与可逆反变换，保证输出范围稳定。

- 训练工程与可观测性建设

  - DDP/单卡可切换：支持 USE_DDP
    环境开关；构建单卡快速调试脚本（单进程、NUM_DATA_WORKERS=0）与多卡脚本（torchrun）。

  - 混合精度与梯度稳定：GradScaler + clip_grad_norm；参数统计（总量
    373,081，约 1.42MB fp32），显存/CPU
    监控（alloc/reserved/peak），batch 级 timing（数据获取 vs 前向）。

  - 调试工具集：单样本 forward
    最小化验证、严密日志（\[SANITY\]/\[TIMING\]/\[MEM\]）、梯度 NaN/Inf
    扫描、数据/边属性归一化统计；关键报错（UnboundLocalError、设备断言）均已复现-定位-修复。

- 当前产物（十月）

  - 代码侧：严格重映射模块、运行期断言、Pooling 安全化、per-feature
    残差与局部 LN、训练与调试脚本（单卡/多卡）。

  - 日志侧：端到端首批稳定前向日志（含 SANITY
    边界、TIMING、MEM）、异常定位过程记录。

  - 训练基线：单样本前向与小批量训练已稳定跑通（不再触发 CUDA
    设备断言/索引越界）。

**4. 子课题四研究进展中遇到的问题及对策**

- 问题 A --- 设备断言（CUDA device-side assert）

  - 原因：pool 后 N 与 river/causal 边索引上界不一致（父键稀疏）。

  - 对策：严格 remap（裁剪 + 0..K-1 连续重编号），GraphPooling
    安全化，前向入口断言（river vs N、causal vs N\*F）。

- 问题 B ---首 batch 过慢 / SIGABRT

  - 原因：索引不一致引发前向内核异常 + 多进程/多 worker 放大开销。

  - 对策：单卡无 worker 基线 + 单样本 forward 验证 + TIMING
    埋点；修复后再逐步恢复并行。

- 问题 C ---数值稳定与 dtype 对齐

  - 原因：半精混合下 embedding/LayerNorm dtype 不一致。

  - 对策：在关键路径手动 cast 到激活 dtype；局部 LN 替代全局 reshape。

**4. 子课题四下一步工作计划(2025.10.20-2025.1.20)**

- 高优先级

  - 时间维向量化重构：将 (B,N,H,T) → (B\*T,N,H) 合批调用 river/causal
    图卷积，消除 Python 双重循环；预计前向 3--8× 加速。

  - 建立训练指标基线：单卡完整训练（RMSE/MAE/R²），形成基线曲线与资源曲线；在此基础上再恢复多卡验证扩展性。

- 中优先级

  - GraphPooling/Unpooling 向量化：移除 Python for，使用张量化
    scatter/gather。

  - 训练采样与缓存：RandomSubsetDistributedSampler、窗口离线缓存（.pt）以降低
    epoch 时间。

  - 物理一致性约束：引入软约束（如非负/守恒相关项）评估泛化与可解释性提升。

- 低优先级

  - 多尺度预测融合策略对比（coarse→fine 引导、多层输出加权）

  - 可视化监控接入（TensorBoard/W&B）与指标面板
